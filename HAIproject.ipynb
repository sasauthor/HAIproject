{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvTQ9M1gc2lL",
        "outputId": "3a4a54ea-a009-41ff-d27f-dd17905dd971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dmfont'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 83 (delta 12), reused 6 (delta 6), pack-reused 61 (from 1)\u001b[K\n",
            "Receiving objects: 100% (83/83), 192.23 KiB | 974.00 KiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/dmfont\n"
          ]
        }
      ],
      "source": [
        "#기본 설치\n",
        "!git clone https://github.com/clovaai/dmfont.git\n",
        "%cd dmfont"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow PyYAML tqdm scikit-image imageio matplotlib fire fonttools tensorboardX sconf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tsuua-wdLpy",
        "outputId": "3a50f3f7-0e3d-44bb-9ff5-54c14db576d0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.11/dist-packages (4.58.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sconf\n",
            "  Downloading sconf-0.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.21)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.4)\n",
            "Collecting ruamel.yaml (from sconf)\n",
            "  Downloading ruamel.yaml-0.18.12-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting munch (from sconf)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->sconf)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sconf-0.2.5-py3-none-any.whl (8.8 kB)\n",
            "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading ruamel.yaml-0.18.12-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=533d785db6a6684f17b3bf41e08672fc5c1922246ece748cc0dfb4f00ed1ff73\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: tensorboardX, ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, fire, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, sconf, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed fire-0.7.0 munch-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruamel.yaml-0.18.12 ruamel.yaml.clib-0.2.12 sconf-0.2.5 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wamw5o-Qf3R7",
        "outputId": "cafd5170-163d-4ca4-a4a6-6abd389f3cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints/\n",
        "!cp \"/content/drive/Shareddrives/2025 인공프/dmfont/korean-handwriting.pth\" checkpoints/\n",
        "\n",
        "!mkdir -p data/charset/\n",
        "!cp \"/content/drive/Shareddrives/2025 인공프/dmfont/korean11172.txt\" data/charset\n",
        "\n",
        "!mkdir -p style\n",
        "!cp \"/content/drive/Shareddrives/2025 인공프/dmfont/Styleimg.pdf\" style\n",
        "\n",
        "import os\n",
        "os.makedirs(\"configs\", exist_ok=True)"
      ],
      "metadata": {
        "id": "ulE8IBTliFkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils  # pdf2image에서 필요\n",
        "!pip install pdf2image\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "pdf_files = [\n",
        "    \"/content/dmfont/style/Styleimg.pdf\",\n",
        "]\n",
        "\n",
        "output_dir = \"/content/dmfont/style\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for pdf_path in pdf_files:\n",
        "    images = convert_from_path(pdf_path, dpi=300)\n",
        "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "\n",
        "    if len(images) > 1:\n",
        "        # 여러 페이지면 _p1, _p2 등 붙임\n",
        "        for i, img in enumerate(images):\n",
        "            out_path = f\"{output_dir}/{base_name}_p{i+1}.png\"\n",
        "            img.save(out_path)\n",
        "            print(f\"✅ 저장 완료: {out_path}\")\n",
        "    else:\n",
        "        # 한 페이지만 있으면 기본 이름으로 저장\n",
        "        img = images[0]\n",
        "        out_path = f\"{output_dir}/{base_name}.png\"\n",
        "        img.save(out_path)\n",
        "        print(f\"✅ 저장 완료: {out_path}\")\n",
        "\n",
        "from PIL import Image, ImageChops\n",
        "import os\n",
        "\n",
        "def trim_whitespace(path):\n",
        "    img = Image.open(path)\n",
        "    bg = Image.new(img.mode, img.size, img.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(img, bg)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        trimmed = img.crop(bbox)\n",
        "        trimmed.save(path)  # 덮어쓰기\n",
        "        print(f\"✅ 여백 제거 완료: {path}\")\n",
        "    else:\n",
        "        print(f\"⚠ 여백 없음: {path}\")\n",
        "\n",
        "# data/raw 안의 모든 이미지 여백 제거\n",
        "for fname in os.listdir(\"/content/dmfont/style\"):\n",
        "    if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        trim_whitespace(f\"/content/dmfont/style/{fname}\")\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "raw_dir = \"/content/dmfont/style\"\n",
        "\n",
        "for fname in os.listdir(raw_dir):\n",
        "    if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        path = os.path.join(raw_dir, fname)\n",
        "        img = Image.open(path)\n",
        "        img.save(path, dpi=(300, 300))  # 해상도만 300dpi로 설정\n",
        "        print(f\"✅ 해상도 300dpi 저장 완료: {fname}\")\n",
        "\n",
        "crop_code = '''\n",
        "import os\n",
        "from PIL import Image, ImageChops, ImageOps\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--src_dir\", required=True)\n",
        "parser.add_argument(\"--dst_dir\", required=True)\n",
        "args = parser.parse_args()\n",
        "\n",
        "# 각 템플릿별 행, 열\n",
        "layout = {\n",
        "    \"Styleimg.png\": (4, 7)\n",
        "}\n",
        "\n",
        "pad = 20\n",
        "os.makedirs(args.dst_dir, exist_ok=True)\n",
        "\n",
        "start_unicode = 0xAC00\n",
        "count = 0\n",
        "\n",
        "skip_indices = {\n",
        "    \"Styleimg.png\": set()  # 건너뛸 칸이 없으면 빈 set()\n",
        "}\n",
        "\n",
        "for fname in sorted(os.listdir(args.src_dir)):\n",
        "    if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        continue\n",
        "\n",
        "    if fname not in layout:\n",
        "        print(f\"⚠ {fname}의 행/열 정보가 layout에 없습니다. 건너뜀.\")\n",
        "        continue\n",
        "\n",
        "    rows, cols = layout[fname]\n",
        "    skip_set = skip_indices.get(fname, set())\n",
        "\n",
        "    img_path = os.path.join(args.src_dir, fname)\n",
        "    img = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "    w, h = img.size\n",
        "    cell_w = w // cols\n",
        "    cell_h = h // rows\n",
        "\n",
        "    index = 1  # 1부터 시작\n",
        "\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if index in skip_set:\n",
        "                print(f\"⏩ {fname} - 칸 {index} 건너뜀\")\n",
        "                index += 1\n",
        "                continue\n",
        "\n",
        "            left = c * cell_w + pad\n",
        "            upper = r * cell_h + pad + 40\n",
        "            right = (c + 1) * cell_w - pad\n",
        "            lower = (r + 1) * cell_h - pad\n",
        "            cropped = img.crop((left, upper, right, lower))\n",
        "\n",
        "            bg = Image.new(\"L\", cropped.size, 255)\n",
        "            diff = ImageChops.difference(cropped, bg)\n",
        "            bbox = diff.getbbox()\n",
        "\n",
        "            if bbox:\n",
        "                cropped = cropped.crop(bbox)\n",
        "\n",
        "            padding = 30\n",
        "            cropped = ImageOps.expand(cropped, border=padding, fill=255)\n",
        "\n",
        "            # 정사각형 배경 만들고 중앙 배치\n",
        "            max_side = max(cropped.size)\n",
        "            square = Image.new(\"L\", (max_side, max_side), 255)\n",
        "            offset = ((max_side - cropped.width) // 2, (max_side - cropped.height) // 2)\n",
        "            square.paste(cropped, offset)\n",
        "            cropped = square\n",
        "\n",
        "            # 최종 리사이즈\n",
        "            cropped = cropped.resize((512, 512), Image.BICUBIC)\n",
        "\n",
        "            fname_out = f\"uni{start_unicode + count:04X}.png\"\n",
        "            cropped.save(os.path.join(args.dst_dir, fname_out))\n",
        "            count += 1\n",
        "            index += 1\n",
        "\n",
        "print(f\"✅ 총 {count}개 글자 이미지 저장 완료: {args.dst_dir}\")\n",
        "'''\n",
        "\n",
        "with open(\"/content/dmfont/style/crop.py\", \"w\") as f:\n",
        "    f.write(crop_code)\n",
        "\n",
        "print(\"✅ crop.py 생성 완료\")\n",
        "\n",
        "!python style/crop.py \\\n",
        "  --src_dir=style \\\n",
        "  --dst_dir=style/cropped\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-eCCvboYfrJ",
        "outputId": "93dba7d1-d096-4d63-b8ba-37b5ca4318a6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.2.1)\n",
            "✅ 저장 완료: /content/dmfont/style/Styleimg.png\n",
            "✅ 여백 제거 완료: /content/dmfont/style/Styleimg.png\n",
            "✅ 해상도 300dpi 저장 완료: Styleimg.png\n",
            "✅ crop.py 생성 완료\n",
            "✅ 총 28개 글자 이미지 저장 완료: style/cropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "src_folder = \"style/cropped\"\n",
        "dst_folder = \"style_cleaned\"\n",
        "os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "for fname in os.listdir(src_folder):\n",
        "    if fname.lower().endswith(\".png\"):\n",
        "        # 이미지 열기 및 흑백화\n",
        "        img = Image.open(os.path.join(src_folder, fname)).convert(\"L\")\n",
        "\n",
        "        # NumPy 배열로 변환\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # threshold 적용 (0 또는 255로 변환)\n",
        "        threshold = 200\n",
        "        img_bin = np.where(img_np > threshold, 255, 0).astype(np.uint8)\n",
        "\n",
        "        # 다시 이미지로 변환\n",
        "        img_cleaned = Image.fromarray(img_bin, mode=\"L\")\n",
        "\n",
        "        # 리사이즈\n",
        "        img_cleaned = img_cleaned.resize((128, 128), Image.Resampling.LANCZOS)\n",
        "\n",
        "        # 저장\n",
        "        img_cleaned.save(os.path.join(dst_folder, fname))\n"
      ],
      "metadata": {
        "id": "F2C_Myw0tOi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "cfg = {\n",
        "    'style_imgs': [\n",
        "        'style_cleaned/uniAC00.png',\n",
        "        'style_cleaned/uniAC01.png',\n",
        "        'style_cleaned/uniAC02.png',\n",
        "        'style_cleaned/uniAC03.png',\n",
        "        'style_cleaned/uniAC04.png',\n",
        "        'style_cleaned/uniAC05.png',\n",
        "        'style_cleaned/uniAC06.png',\n",
        "        'style_cleaned/uniAC07.png',\n",
        "        'style_cleaned/uniAC08.png',\n",
        "        'style_cleaned/uniAC09.png',\n",
        "        'style_cleaned/uniAC0A.png',\n",
        "        'style_cleaned/uniAC0B.png',\n",
        "        'style_cleaned/uniAC0C.png',\n",
        "        'style_cleaned/uniAC0D.png',\n",
        "        'style_cleaned/uniAC0E.png',\n",
        "        'style_cleaned/uniAC0F.png',\n",
        "        'style_cleaned/uniAC10.png',\n",
        "        'style_cleaned/uniAC11.png',\n",
        "        'style_cleaned/uniAC12.png',\n",
        "        'style_cleaned/uniAC13.png',\n",
        "        'style_cleaned/uniAC14.png',\n",
        "        'style_cleaned/uniAC15.png',\n",
        "        'style_cleaned/uniAC16.png',\n",
        "        'style_cleaned/uniAC17.png',\n",
        "        'style_cleaned/uniAC18.png',\n",
        "        'style_cleaned/uniAC19.png',\n",
        "        'style_cleaned/uniAC1A.png',\n",
        "        'style_cleaned/uniAC1B.png'\n",
        "    ],\n",
        "    'style_chars': ['각','깪','냓','댼','떥','렎','멷','볠','뽉','솲','쐛','욄','죭','쭖','춣','퀨','튑','퓺','흣','읬','잉','잊','잋','잌','잍','잎','잏','이'],\n",
        "\n",
        "    'charset_path': 'data/charset/korean11172.txt',\n",
        "    'output_dir': 'output',\n",
        "    'checkpoint': 'checkpoints/korean-handwriting.pth',\n",
        "    'num_font_samples': 1,\n",
        "    'target_chars': ['가','나','다','라','마','바','사','아','자','차','카','타','파','하','\\n','안','녕','하','세','요','\\n','감','사','합','니','다','\\n','구','름','빵',' ','먹','고','싶','다','\\n','오','늘',' ','저','녁','은',' ','고','추','잡','채','밥'],\n",
        "\n",
        "    'C': 32,\n",
        "    'n_comps': 68,\n",
        "    'n_comp_types': 3,\n",
        "    'language': 'kor'\n",
        "}\n",
        "\n",
        "with open('configs/infer_colab.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f, allow_unicode=True)\n"
      ],
      "metadata": {
        "id": "VF-e0Tm3t1Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### class StyleImageDataset 정의\n",
        "\n",
        "import os\n",
        "\n",
        "code = \"\"\"\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from . import kor_decompose\n",
        "\n",
        "class StyleImageDataset(Dataset):\n",
        "    def __init__(self, style_imgs, style_chars, language='kor', transform=None, style_id=0):\n",
        "        assert len(style_imgs) == len(style_chars), \"style_imgs와 style_chars 길이는 같아야 합니다.\"\n",
        "        self.style_imgs = style_imgs\n",
        "        self.style_chars = style_chars\n",
        "        self.language = language\n",
        "        self.transform = transform\n",
        "        self.style_id = style_id\n",
        "\n",
        "        if language == 'kor':\n",
        "            self.decompose = kor_decompose.decompose\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Language {language}는 지원되지 않습니다.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.style_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.style_imgs[idx]\n",
        "        char = self.style_chars[idx]\n",
        "        comp_ids = self.decompose(char)\n",
        "\n",
        "        img = Image.open(path).convert('L')  # 흑백\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return (\n",
        "            self.style_id,\n",
        "            torch.as_tensor(comp_ids),\n",
        "            img\n",
        "        )\n",
        "\"\"\"\n",
        "\n",
        "os.makedirs(\"dmfont/datasets\", exist_ok=True)\n",
        "with open(\"datasets/style_image_dataset.py\", \"w\") as f:\n",
        "    f.write(code.strip())\n",
        "\n"
      ],
      "metadata": {
        "id": "EQ6emfp2JsfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "####inference.py 수정\n",
        "\n",
        "# 덮어쓸 내용 정의 (여러 줄 문자열)\n",
        "new_code = '''\n",
        "\n",
        "\"\"\"\n",
        "DMFont\n",
        "Copyright (c) 2020-present NAVER Corp.\n",
        "MIT license\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import get_ma_val_dataset\n",
        "from datasets.nonpaired_dataset import EncodeDataset, DecodeDataset\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/dmfont\")  # or wherever your 'style_cleaned' 폴더가 있는 최상위 경로\n",
        "\n",
        "\n",
        "\n",
        "def get_val_loader(data, fonts, chars, style_avails, transform, content_font, language,\n",
        "                   B=32, n_max_match=3, n_workers=2):\n",
        "    val_dset, collate_fn = get_ma_val_dataset(\n",
        "        data, fonts, chars, style_avails, n_max_match, transform=transform,\n",
        "        content_font=content_font, language=language\n",
        "    )\n",
        "    loader = DataLoader(val_dset, batch_size=B, shuffle=False,\n",
        "                        num_workers=n_workers, collate_fn=collate_fn)\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "def infer_2stage(gen, encode_loader, decode_loader, reset_memory=True):\n",
        "    \"\"\" 2-stage infer; encode first, decode second \"\"\"\n",
        "    # stage 1. encode\n",
        "    if reset_memory:\n",
        "        gen.reset_dynamic_memory()\n",
        "\n",
        "    for style_ids, style_comp_ids, style_imgs in encode_loader:\n",
        "        style_ids = style_ids.to(\"cpu\")\n",
        "        style_comp_ids = style_comp_ids.to(\"cpu\")\n",
        "        style_imgs = style_imgs.to(\"cpu\")\n",
        "\n",
        "        gen.encode_write(style_ids, style_comp_ids, style_imgs, reset_dynamic_memory=False)\n",
        "\n",
        "    # stage 2. decode\n",
        "    outs = []\n",
        "    for trg_ids, trg_comp_ids in decode_loader:\n",
        "        trg_ids = trg_ids.to(\"cpu\")\n",
        "        trg_comp_ids = trg_comp_ids.to(\"cpu\")\n",
        "        # print(\"🧠 target_style_ids:\", style_ids)\n",
        "\n",
        "\n",
        "        out = gen.read_decode(trg_ids, trg_comp_ids)\n",
        "\n",
        "        outs.append(out.detach().cpu())\n",
        "\n",
        "    return torch.cat(outs)\n",
        "\n",
        "\n",
        "def get_val_decode_loader(chars, language, B=32, num_workers=2, style_id=0):\n",
        "    decode_dset = DecodeDataset(chars, language=language, style_id=style_id)\n",
        "    loader = DataLoader(decode_dset, batch_size=B, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "\n",
        "###추가\n",
        "from datasets.style_image_dataset import StyleImageDataset  # 직접 만든 Dataset일 수도 있음\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_styleimg_encode_loader(style_imgs, style_chars, language, transform, style_id=0, B=32, num_workers=2):\n",
        "    dset = StyleImageDataset(style_imgs, style_chars, language=language, transform=transform, style_id=style_id)\n",
        "    return DataLoader(dset, batch_size=B, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "def get_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ])\n",
        "\n",
        "#수정후\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def save_sentence_image(\n",
        "    imgs, path, text=None, target_height=128,\n",
        "    max_side_crop1=25, max_side_crop2=25,\n",
        "    overlap_margin=0, space_margin=30, line_spacing=20\n",
        "):\n",
        "    imgs = imgs.squeeze(1)  # [N, 1, H, W] → [N, H, W]\n",
        "    imgs = imgs.mul(0.5).add(0.5).clamp(0, 1)  # [-1,1] → [0,1]\n",
        "    imgs = imgs.mul(255).byte().cpu().numpy()  # [0,255]\n",
        "\n",
        "    # 문자 이미지 전처리\n",
        "    char_imgs = []\n",
        "    for img in imgs:\n",
        "        pil_img = Image.fromarray(img, mode='L')\n",
        "        arr = np.array(pil_img)\n",
        "\n",
        "        col_sum = np.mean(arr, axis=0)\n",
        "        non_white = np.where(col_sum < 245)[0]\n",
        "        if len(non_white) > 0:\n",
        "            x0 = max(non_white[0] - max_side_crop1, 0)\n",
        "            x1 = min(non_white[-1] + max_side_crop2 + 1, arr.shape[1])\n",
        "            cropped = pil_img.crop((x0, 0, x1, arr.shape[0]))\n",
        "        else:\n",
        "            cropped = pil_img\n",
        "\n",
        "        # 높이 맞춤\n",
        "        W, H = cropped.size\n",
        "        if H < target_height:\n",
        "            top_pad = (target_height - H) // 2\n",
        "            padded = Image.new('L', (W, target_height), 255)\n",
        "            padded.paste(cropped, (0, top_pad))\n",
        "        else:\n",
        "            padded = cropped.resize((W, target_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "        char_imgs.append(padded)\n",
        "\n",
        "    # 총 이미지 크기 계산\n",
        "    max_line_width = 0\n",
        "    line_width = 0\n",
        "    img_idx = 0\n",
        "    line_count = 1\n",
        "    for c in text:\n",
        "        if c == '\\\\n':\n",
        "            max_line_width = max(max_line_width, line_width)\n",
        "            line_width = 0\n",
        "            line_count += 1\n",
        "        elif c == ' ':\n",
        "            line_width += space_margin\n",
        "        else:\n",
        "            if img_idx < len(char_imgs):\n",
        "                line_width += char_imgs[img_idx].size[0]\n",
        "                if line_width > 0:\n",
        "                    line_width -= overlap_margin\n",
        "                img_idx += 1\n",
        "    max_line_width = max(max_line_width, line_width)\n",
        "    total_height = line_count * target_height + (line_count - 1) * line_spacing\n",
        "\n",
        "    # 이미지 생성 및 붙이기\n",
        "    final_img = Image.new('L', (max_line_width, total_height), 255)\n",
        "    x_offset = 0\n",
        "    y_offset = 0\n",
        "    img_idx = 0\n",
        "\n",
        "    for c in text:\n",
        "        if c == '\\\\n':\n",
        "            y_offset += target_height + line_spacing\n",
        "            x_offset = 0\n",
        "        elif c == ' ':\n",
        "            x_offset += space_margin\n",
        "        else:\n",
        "            if img_idx >= len(char_imgs):\n",
        "                break\n",
        "            im = char_imgs[img_idx]\n",
        "            final_img.paste(im, (x_offset, y_offset))\n",
        "            x_offset += im.size[0] - overlap_margin\n",
        "            img_idx += 1\n",
        "\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    final_img.save(path)\n",
        "\n",
        "\n",
        "def main(config, checkpoint, save_dir):\n",
        "    import os\n",
        "    import torch\n",
        "    import yaml\n",
        "    with open(config, 'r') as f:\n",
        "      cfg = yaml.safe_load(f)\n",
        "    from models.comp_encoder import ComponentEncoder\n",
        "    from models.decoder import Decoder\n",
        "    from models.ma_core import MACore\n",
        "    # from datasets.transforms import get_transform\n",
        "    # from utils.misc import save_imgs\n",
        "    from inference import infer_2stage, get_val_decode_loader\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    with open(config, 'r') as f:\n",
        "      cfg = yaml.safe_load(f)\n",
        "\n",
        "\n",
        "    # style-aware feed-forward block 설정\n",
        "    sa = {'n_heads': 4}  # Clova 기본 세팅\n",
        "\n",
        "\n",
        "    # 최종 Generator 생성\n",
        "    gen = MACore(\n",
        "        C_in=1,\n",
        "        C=32,              # ← from config\n",
        "        C_out=1,\n",
        "        comp_enc={\n",
        "            'norm': 'none',\n",
        "            'activ': 'relu',\n",
        "            'pad_type': 'zero',\n",
        "            'sa': {\n",
        "                'C_qk_ratio': 0.5,\n",
        "                'n_heads': 2,\n",
        "                'area': False,\n",
        "                'ffn_mult': 2\n",
        "            }\n",
        "        },\n",
        "        dec={\n",
        "            'norm': 'IN',\n",
        "            'activ': 'relu',\n",
        "            'pad_type': 'zero'\n",
        "        },\n",
        "        n_comps=68,\n",
        "        n_comp_types=3,\n",
        "        language='kor'\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 사전학습된 파라미터 로드\n",
        "    ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
        "    gen.load_state_dict(ckpt[\"generator_ema\"])  # ✅ 이거로!\n",
        "\n",
        "    gen.eval()\n",
        "\n",
        "    # 인코딩 및 디코딩용 데이터로더\n",
        "    from inference import get_styleimg_encode_loader  # 위에서 만든 함수\n",
        "\n",
        "    encode_loader = get_styleimg_encode_loader(\n",
        "      cfg['style_imgs'], cfg['style_chars'], cfg['language'],\n",
        "      transform=get_transform(), style_id=0\n",
        "    )\n",
        "    import re\n",
        "    valid_target_chars = [c for c in cfg['target_chars'] if re.match(r'[가-힣]', c)]\n",
        "    decode_loader = get_val_decode_loader(valid_target_chars, cfg['language'], style_id=0)\n",
        "    text = ''.join(cfg['target_chars'])  # 출력용 문장은 그대로 유지\n",
        "\n",
        "\n",
        "    # 추론 실행\n",
        "    with torch.no_grad():\n",
        "        outs = infer_2stage(gen, encode_loader, decode_loader)\n",
        "\n",
        "    # save_sentence_image_with_padding(outs, os.path.join(save_dir, \"sentence.png\"))\n",
        "    save_sentence_image(outs, os.path.join(save_dir, \"sentence.png\"), text=text, overlap_margin=0, space_margin=50)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import fire\n",
        "    fire.Fire(main)\n",
        "\n",
        "'''\n",
        "\n",
        "# 경로에 덮어쓰기\n",
        "with open('inference.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(new_code)\n"
      ],
      "metadata": {
        "id": "rvwDF4uqKD0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire\n",
        "!python inference.py \\\n",
        "    --config configs/infer_colab.yaml \\\n",
        "    --checkpoint checkpoints/korean-handwriting.pth \\\n",
        "    --save_dir output/"
      ],
      "metadata": {
        "id": "XaJmSUeUuuNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601a58ff-ef8f-4869-bdd5-a8da86ff872b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire) (3.1.0)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    }
  ]
}